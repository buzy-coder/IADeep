apiVersion: v1
kind: Pod   
metadata:
  generateName: lstm-
  namespace: iadeep
  labels:
    app: lstm
spec:
  containers:
    - name: share-gpu-lstm
      image: 10.119.46.41:30003/library/iadeep_benchmarks:1.0
      imagePullPolicy: Always
      env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name  
      command:
        - python
      args: ["/workspace/workloads/job_agent.py", "--job_name=lstm", "--batch_size=256"]
      resources:
        requests:
          cpu: 2
          memory: 10G
          gpushare/gpu-mem: 3
        limits:
          cpu: 2
          memory: 10G
          gpushare/gpu-mem: 3
      volumeMounts:
      - name: datapath
        mountPath: /workspace/dataset/
        readOnly: True
      - name: logpath   
        mountPath: /workspace/workloads/result/
        readOnly: False
      - name: cachepath
        mountPath: /workspace/.vector_cache/
        readOnly: False
      ports:
        - containerPort: 80
  volumes:
  - name: datapath
    hostPath:
      path: /nfs/dataset/
      type: DirectoryOrCreate
  - name: logpath
    hostPath:
      path: /nfs/logs/
      type: DirectoryOrCreate
  - name: cachepath
    hostPath:
      path: /nfs/cache
      type: DirectoryOrCreate

  nodeSelector:
    # kubernetes.io/hostname: slave12
    gpushare: "true"
  restartPolicy: Never
  schedulerName: iadeep-scheduler
